{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"index.html","title":"Welcome to The Director","text":"<p>The Director is an innovative, AI-driven video processing and analysis platform designed to revolutionize how you interact with video content. Built on the powerful infrastructure of VideoDB, The Director leverages a suite of specialized AI agents and advanced language models to manage and execute a wide range of video-related tasks seamlessly.</p> <p>With its modular architecture, The Director makes it easy to expand and integrate new functionalities, adapting effortlessly to diverse use cases. Key features include:</p> <ul> <li>Intelligent Agents: Purpose-built agents handle tasks such as video upload, summarization, chapter creation, search, dubbing, dynamic editing, branding, and publishing.</li> <li>Language Model Integration: Advanced natural language processing capabilities enable intuitive interaction through chat-based workflows.</li> <li>Flexible Database Interface: Efficient storage, retrieval, and indexing for video content ensure seamless data management.</li> </ul> <p>To simplify adoption, The Director provides a streamlined setup process using a Makefile, enabling developers to deploy or customize the platform effortlessly.</p> <p>Whether you're building AI-powered video editors, automating video workflows, or exploring new applications of video intelligence, The Director empowers developers to push the boundaries of what's possible with video.</p>"},{"location":"agents/interface.html","title":"Agents","text":"<p>Agents are the core building blocks of the Video Agent system. They are responsible for processing input messages and generating output messages.</p>"},{"location":"agents/interface.html#agent-interface","title":"Agent Interface","text":"<p>Base Agent is the base class for all agents. It provides a common interface for all agents to follow.</p>"},{"location":"agents/interface.html#base-agent","title":"Base Agent","text":""},{"location":"agents/interface.html#director.agents.base.BaseAgent","title":"director.agents.base.BaseAgent","text":"<pre><code>BaseAgent(session, **kwargs)\n</code></pre> <p>               Bases: <code>ABC</code></p> <p>Interface for all agents. All agents should inherit from this class.</p> Source code in <code>backend/director/agents/base.py</code> <pre><code>def __init__(self, session: Session, **kwargs):\n    self.session: Session = session\n    self.output_message: OutputMessage = self.session.output_message\n</code></pre>"},{"location":"agents/interface.html#director.agents.base.BaseAgent.get_parameters","title":"get_parameters","text":"<pre><code>get_parameters()\n</code></pre> <p>Return the automatically inferred parameters for the function using the dcstring of the function.</p> Source code in <code>backend/director/agents/base.py</code> <pre><code>def get_parameters(self):\n    \"\"\"Return the automatically inferred parameters for the function using the dcstring of the function.\"\"\"\n    function_inferrer = FunctionInferrer.infer_from_function_reference(self.run)\n    function_json = function_inferrer.to_json_schema()\n    parameters = function_json.get(\"parameters\")\n    if not parameters:\n        raise Exception(\n            \"Failed to infere parameters, please define JSON instead of using this automated util.\"\n        )\n\n    parameters[\"properties\"].pop(\"args\", None)\n    parameters[\"properties\"].pop(\"kwargs\", None)\n\n    if \"required\" in parameters:\n        parameters[\"required\"] = [\n            param\n            for param in parameters[\"required\"]\n            if param not in [\"args\", \"kwargs\"]\n        ]\n\n    return parameters\n</code></pre>"},{"location":"agents/interface.html#director.agents.base.BaseAgent.to_llm_format","title":"to_llm_format","text":"<pre><code>to_llm_format()\n</code></pre> <p>Convert the agent to LLM tool format.</p> Source code in <code>backend/director/agents/base.py</code> <pre><code>def to_llm_format(self):\n    \"\"\"Convert the agent to LLM tool format.\"\"\"\n    return {\n        \"name\": self.agent_name,\n        \"description\": self.description,\n        \"parameters\": self.parameters,\n    }\n</code></pre>"},{"location":"agents/interface.html#agent-response","title":"Agent Response","text":""},{"location":"agents/interface.html#director.agents.base.AgentResponse","title":"director.agents.base.AgentResponse  <code>pydantic-model</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Data model for respones from agents.</p>"},{"location":"concepts/overview.html","title":"Overview","text":""},{"location":"concepts/overview.html#architecture-overview","title":"\u2699\ufe0f Architecture Overview","text":"<p>Director's architecture brings together:</p> <p>Backend Reasoning Engine: Handles workflows and decision-making. Check out the backend folder in director codebase.  Chat-Based UI: Engage with your media library conversationally. Check videodb-chat for the source code. Video Player: Advanced playback and interaction tools. Check videodb-player for the details about the multi-platform video player. - Collection View: Organize and browse your media effortlessly.</p> <p></p>"},{"location":"concepts/overview.html#reasoning-engine","title":"Reasoning Engine","text":"<p>The Reasoning Engine is the core component that directly interfaces with the user. It interprets natural language input in any conversation and orchestrates agents to fulfill the user's requests. The primary functions of the Reasoning Engine are:</p> <ul> <li>Maintain Context of Conversational History: Manage memory, context limits, input, and output experiences to ensure coherent and context-aware interactions.</li> <li>Natural Language Understanding (NLU): Uses LLMs of your choice to have understanding of the task. </li> <li>Intelligent Reference Deduction: Intelligently deduce references to previous messages, outputs, files, agents, etc., to provide relevant and accurate responses.</li> <li>Agent Orchestration: Decide on agents and their workflows to fulfill requests. Multiple strategies can be employed to create agent workflows, such as step-by-step processes or chaining of agents provided by default.</li> <li>Final Control Over Conversation Flow: Maintain ultimate control over the flow of conversation with the user, ensuring coherence and goal alignment.</li> </ul>"},{"location":"concepts/overview.html#see-it-in-action","title":"See It in Action","text":"<p>The Reasoning Engine works in tandem with the chat-based UI, making video interaction intuitive and efficient. For example: - Input: \"Create a clip of the funniest scene in this video and share it on Slack.\" - Output: The engine orchestrates upload, scene detection, clipping, and sharing agents to deliver results seamlessly. Watch the video here</p> <p>For a closer look, check out the detailed architecture diagram below: </p>"},{"location":"concepts/overview.html#agents","title":"Agents","text":"<p>An Agent is an autonomous entity that performs specific tasks using available tools. Agents define the user experience and are unique in their own way. Some agents can make the conversation fun while accomplishing tasks, similar to your favorite barista. Others might provide user experiences like a video player, display images, collections of images, or engage in text-based chat. Agents can also have personalities. We plan to add multiple agents for the same tasks but with a variety of user experiences.</p> <p>For example, the task \"Give me a summary of this video\" can be accomplished by choosing one of the summary agents:</p> <ul> <li>\"PromptSummarizer\": This agent asks you for prompts that can be used for generating a summary. You have control and freedom over the style in each interaction.</li> <li>\"SceneSummarizer\": This agent uses scene descriptions, audio, etc., to generate a summary in a specific format using its internal prompt.</li> </ul>"},{"location":"concepts/overview.html#key-aspects-of-agents-include","title":"Key aspects of Agents include:","text":"<ul> <li>Task Autonomy: Agents perform tasks independently, utilizing tools to achieve their objectives.</li> <li>Unique User Experiences (UX): Each agent offers a distinct user experience, enhancing engagement and satisfaction. Multiple agents for the same task offer personalized interactions and cater to different user preferences like loading a specific UI or just a text message.</li> <li>Standardized Agent Interface: Agents communicate with the Reasoning Engine through a common API or protocol, ensuring consistent integration and interaction.</li> </ul>"},{"location":"concepts/overview.html#agent-examples","title":"Agent Examples","text":"<ol> <li>Highlight Creator: link</li> <li>Text to Movie: link</li> <li>Video Search: link</li> </ol>"},{"location":"concepts/overview.html#tools","title":"Tools","text":"<p>Tools are functional building blocks that can be created from any library and used within agents. They are the functions that enable agents to perform their tasks. For example, we have created an upload tool that is a wrapper around the videodb upload function, another one is an index function with parameters.</p>"},{"location":"concepts/overview.html#key-aspects-of-tools-include","title":"Key aspects of Tools include:","text":"<ul> <li>Functional Building Blocks: Serve as modular functions that agents can utilize to perform tasks efficiently.</li> <li>Wrapper Functions: Act as wrappers for existing functions or libraries, enhancing modularity and reusability.</li> </ul>"},{"location":"core/reasoning.html","title":"Reasoning","text":""},{"location":"core/reasoning.html#reasoning-engine","title":"Reasoning Engine","text":""},{"location":"core/reasoning.html#director.core.reasoning.ReasoningEngine","title":"director.core.reasoning.ReasoningEngine","text":"<pre><code>ReasoningEngine(input_message, session)\n</code></pre> <p>The Reasoning Engine is the core class that directly interfaces with the user. It interprets natural language input in any conversation and orchestrates agents to fulfill the user's requests. The primary functions of the Reasoning Engine are:</p> <ul> <li>Maintain Context of Conversational History: Manage memory, context limits, input, and output experiences to ensure coherent and context-aware interactions.</li> <li>Natural Language Understanding (NLU): Uses LLMs of your choice to have understanding of the task.</li> <li>Intelligent Reference Deduction: Intelligently deduce references to previous messages, outputs, files, agents, etc., to provide relevant and accurate responses.</li> <li>Agent Orchestration: Decide on agents and their workflows to fulfill requests. Multiple strategies can be employed to create agent workflows, such as step-by-step processes or chaining of agents provided by default.</li> <li>Final Control Over Conversation Flow: Maintain ultimate control over the flow of conversation with the user, ensuring coherence and goal alignment.</li> </ul> <p>Initialize the ReasoningEngine with the input message and session.</p> <p>Parameters:</p> Name Type Description Default <code>input_message</code> <code>InputMessage</code> <p>The input message to the reasoning engine.</p> required <code>session</code> <code>Session</code> <p>The session instance.</p> required Source code in <code>backend/director/core/reasoning.py</code> <pre><code>def __init__(\n    self,\n    input_message: InputMessage,\n    session: Session,\n):\n    \"\"\"Initialize the ReasoningEngine with the input message and session.\n\n    :param input_message: The input message to the reasoning engine.\n    :param session: The session instance.\n    \"\"\"\n    self.input_message = input_message\n    self.session = session\n    self.system_prompt = REASONING_SYSTEM_PROMPT\n    self.max_iterations = 10\n    self.llm = get_default_llm()\n    self.agents: List[BaseAgent] = []\n    self.stop_flag = False\n    self.output_message: OutputMessage = self.session.output_message\n    self.summary_content = None\n    self.failed_agents = []\n</code></pre>"},{"location":"core/reasoning.html#director.core.reasoning.ReasoningEngine.register_agents","title":"register_agents","text":"<pre><code>register_agents(agents)\n</code></pre> <p>Register an agents.</p> <p>Parameters:</p> Name Type Description Default <code>agents</code> <code>List[BaseAgent]</code> <p>The list of agents to register.</p> required Source code in <code>backend/director/core/reasoning.py</code> <pre><code>def register_agents(self, agents: List[BaseAgent]):\n    \"\"\"Register an agents.\n\n    :param agents: The list of agents to register.\n    \"\"\"\n    self.agents.extend(agents)\n</code></pre>"},{"location":"core/reasoning.html#director.core.reasoning.ReasoningEngine.build_context","title":"build_context","text":"<pre><code>build_context()\n</code></pre> <p>Build the context for the reasoning engine it adds the information about the video or collection to the reasoning context.</p> Source code in <code>backend/director/core/reasoning.py</code> <pre><code>def build_context(self):\n    \"\"\"Build the context for the reasoning engine it adds the information about the video or collection to the reasoning context.\"\"\"\n    input_context = ContextMessage(\n        content=self.input_message.content, role=RoleTypes.user\n    )\n    if self.session.reasoning_context:\n        self.session.reasoning_context.append(input_context)\n    else:\n        if self.session.video_id:\n            video = self.session.state[\"video\"]\n            self.session.reasoning_context.append(\n                ContextMessage(\n                    content=self.system_prompt\n                    + f\"\"\"\\nThis is a video in the collection titled {self.session.state[\"collection\"].name} collection_id is {self.session.state[\"collection\"].id} \\nHere is the video refer to this for search, summary and editing \\n- title: {video.name}, video_id: {video.id}, media_description: {video.description}, length: {video.length}\"\"\"\n                )\n            )\n        else:\n            videos = self.session.state[\"collection\"].get_videos()\n            video_title_list = []\n            for video in videos:\n                video_title_list.append(\n                    f\"\\n- title: {video.name}, video_id: {video.id}, media_description: {video.description}, length: {video.length}, video_stream: {video.stream_url}\"\n                )\n            video_titles = \"\\n\".join(video_title_list)\n            images = self.session.state[\"collection\"].get_images()\n            image_title_list = []\n            for image in images:\n                image_title_list.append(\n                    f\"\\n- title: {image.name}, image_id: {image.id}, url: {image.url}\"\n                )\n            image_titles = \"\\n\".join(image_title_list)\n            self.session.reasoning_context.append(\n                ContextMessage(\n                    content=self.system_prompt\n                    + f\"\"\"\\nThis is a collection of videos and the collection description is {self.session.state[\"collection\"].description} and collection_id is {self.session.state[\"collection\"].id} \\n\\nHere are the videos in this collection user may refer to them for search, summary and editing {video_titles}\\n\\nHere are the images in this collection {image_titles}\"\"\"\n                )\n            )\n        self.session.reasoning_context.append(input_context)\n</code></pre>"},{"location":"core/reasoning.html#director.core.reasoning.ReasoningEngine.run_agent","title":"run_agent","text":"<pre><code>run_agent(agent_name, *args, **kwargs)\n</code></pre> <p>Run an agent with the given name and arguments.</p> <p>Parameters:</p> Name Type Description Default <code>agent_name</code> <code>str</code> <p>The name of the agent to run</p> required <code>args</code> <p>The arguments to pass to the agent</p> <code>()</code> <code>kwargs</code> <p>The keyword arguments to pass to the agent</p> <code>{}</code> <p>Returns:</p> Type Description <code>AgentResponse</code> <p>The response from the agent</p> Source code in <code>backend/director/core/reasoning.py</code> <pre><code>def run_agent(self, agent_name: str, *args, **kwargs) -&gt; AgentResponse:\n    \"\"\"Run an agent with the given name and arguments.\n\n    :param str agent_name: The name of the agent to run\n    :param args: The arguments to pass to the agent\n    :param kwargs: The keyword arguments to pass to the agent\n    :return: The response from the agent\n    \"\"\"\n    print(\"-\" * 40, f\"Running {agent_name} Agent\", \"-\" * 40)\n    print(kwargs, \"\\n\\n\")\n\n    agent = next(\n        (agent for agent in self.agents if agent.agent_name == agent_name), None\n    )\n    self.output_message.actions.append(f\"Running @{agent_name} agent\")\n    self.output_message.agents.append(agent_name)\n    self.output_message.push_update()\n    return agent.safe_call(*args, **kwargs)\n</code></pre>"},{"location":"core/reasoning.html#director.core.reasoning.ReasoningEngine.stop","title":"stop","text":"<pre><code>stop()\n</code></pre> <p>Flag the tool to stop processing and exit the run() thread.</p> Source code in <code>backend/director/core/reasoning.py</code> <pre><code>def stop(self):\n    \"\"\"Flag the tool to stop processing and exit the run() thread.\"\"\"\n    self.stop_flag = True\n</code></pre>"},{"location":"core/reasoning.html#director.core.reasoning.ReasoningEngine.step","title":"step","text":"<pre><code>step()\n</code></pre> <p>Run a single step of the reasoning engine.</p> Source code in <code>backend/director/core/reasoning.py</code> <pre><code>def step(self):\n    \"\"\"Run a single step of the reasoning engine.\"\"\"\n    status = AgentStatus.ERROR\n    temp_messages = []\n    max_tries = 1\n    tries = 0\n\n    while status != AgentStatus.SUCCESS:\n        if self.stop_flag:\n            break\n\n        tries += 1\n        if tries &gt; max_tries:\n            break\n        print(\"-\" * 40, \"Context\", \"-\" * 40)\n        print(\n            [message.to_llm_msg() for message in self.session.reasoning_context],\n            \"\\n\\n\",\n        )\n        llm_response: LLMResponse = self.llm.chat_completions(\n            messages=[\n                message.to_llm_msg() for message in self.session.reasoning_context\n            ]\n            + temp_messages,\n            tools=[agent.to_llm_format() for agent in self.agents],\n        )\n        logger.info(f\"LLM Response: {llm_response}\")\n\n        if not llm_response.status:\n            self.output_message.content.append(\n                TextContent(\n                    text=llm_response.content,\n                    status=MsgStatus.error,\n                    status_message=\"Error in reasoning\",\n                    agent_name=\"assistant\",\n                )\n            )\n            self.output_message.actions.append(\"Failed to reason the message\")\n            self.output_message.status = MsgStatus.error\n            self.output_message.publish()\n            self.stop()\n            break\n\n        if llm_response.tool_calls:\n            if self.summary_content:\n                self.remove_summary_content()\n\n            self.session.reasoning_context.append(\n                ContextMessage(\n                    content=llm_response.content,\n                    tool_calls=llm_response.tool_calls,\n                    role=RoleTypes.assistant,\n                )\n            )\n            for tool_call in llm_response.tool_calls:\n                agent_response: AgentResponse = self.run_agent(\n                    tool_call[\"tool\"][\"name\"],\n                    **tool_call[\"tool\"][\"arguments\"],\n                )\n                if agent_response.status == AgentStatus.ERROR:\n                    self.failed_agents.append(tool_call[\"tool\"][\"name\"])\n                self.session.reasoning_context.append(\n                    ContextMessage(\n                        content=agent_response.__str__(),\n                        tool_call_id=tool_call[\"id\"],\n                        role=RoleTypes.tool,\n                    )\n                )\n                print(\"-\" * 40, \"Agent Response\", \"-\" * 40)\n                print(agent_response, \"\\n\\n\")\n                status = agent_response.status\n\n        if not self.summary_content:\n            self.add_summary_content()\n\n        if (\n            llm_response.finish_reason == \"stop\"\n            or llm_response.finish_reason == \"end_turn\"\n            or self.iterations == 0\n        ):\n            self.session.reasoning_context.append(\n                ContextMessage(\n                    content=llm_response.content,\n                    role=RoleTypes.assistant,\n                )\n            )\n            if self.iterations == self.max_iterations - 1:\n                # Direct response case\n                self.summary_content.status_message = \"Here is the response\"\n                self.summary_content.text = llm_response.content\n                self.summary_content.status = MsgStatus.success\n            else:\n                self.session.reasoning_context.append(\n                    ContextMessage(\n                        content=SUMMARIZATION_PROMPT.format(\n                            query=self.input_message.content\n                        ),\n                        role=RoleTypes.system,\n                    )\n                )\n                summary_response = self.llm.chat_completions(\n                    messages=[\n                        message.to_llm_msg()\n                        for message in self.get_current_run_context()\n                    ]\n                )\n                self.session.reasoning_context.pop()\n                self.summary_content.text = summary_response.content\n                if self.failed_agents:\n                    self.summary_content.status = MsgStatus.error\n                else:\n                    self.summary_content.status = MsgStatus.success\n                self.summary_content.status_message = \"Final Cut\"\n            self.output_message.status = MsgStatus.success\n            self.output_message.publish()\n            print(\"-\" * 40, \"Stopping\", \"-\" * 40)\n            self.stop()\n            break\n</code></pre>"},{"location":"core/reasoning.html#director.core.reasoning.ReasoningEngine.run","title":"run","text":"<pre><code>run(max_iterations=None)\n</code></pre> <p>Run the reasoning engine.</p> <p>Parameters:</p> Name Type Description Default <code>max_iterations</code> <code>int</code> <p>The number of max_iterations to run the reasoning engine</p> <code>None</code> Source code in <code>backend/director/core/reasoning.py</code> <pre><code>def run(self, max_iterations: int = None):\n    \"\"\"Run the reasoning engine.\n\n    :param int max_iterations: The number of max_iterations to run the reasoning engine\n    \"\"\"\n    self.iterations = max_iterations or self.max_iterations\n    self.build_context()\n    self.output_message.actions.append(\"Reasoning the message..\")\n    self.output_message.push_update()\n\n    it = 0\n    while self.iterations &gt; 0:\n        self.iterations -= 1\n        print(\"-\" * 40, \"Reasoning Engine Iteration\", it, \"-\" * 40)\n        if self.stop_flag:\n            break\n\n        self.step()\n        it = it + 1\n\n    self.session.save_context_messages()\n    print(\"-\" * 40, \"Reasoning Engine Finished\", \"-\" * 40)\n</code></pre>"},{"location":"core/session.html","title":"Session","text":""},{"location":"core/session.html#session","title":"Session","text":""},{"location":"core/session.html#basemessage","title":"BaseMessage","text":""},{"location":"core/session.html#director.core.session.BaseMessage","title":"director.core.session.BaseMessage  <code>pydantic-model</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Base message class for the input/output message. All the input/output messages will be inherited from this class.</p> <p>Config:</p> <ul> <li><code>arbitrary_types_allowed</code>: <code>True</code></li> <li><code>use_enum_values</code>: <code>True</code></li> <li><code>validate_default</code>: <code>True</code></li> </ul> <p>Fields:</p> <ul> <li> <code>session_id</code>                 (<code>str</code>)             </li> <li> <code>conv_id</code>                 (<code>str</code>)             </li> <li> <code>msg_type</code>                 (<code>MsgType</code>)             </li> <li> <code>actions</code>                 (<code>List[str]</code>)             </li> <li> <code>agents</code>                 (<code>List[str]</code>)             </li> <li> <code>content</code>                 (<code>List[Union[dict, TextContent, ImageContent, VideoContent, VideosContent, SearchResultsContent]]</code>)             </li> <li> <code>status</code>                 (<code>MsgStatus</code>)             </li> <li> <code>msg_id</code>                 (<code>str</code>)             </li> </ul>"},{"location":"core/session.html#inputmessage","title":"InputMessage","text":""},{"location":"core/session.html#director.core.session.InputMessage","title":"director.core.session.InputMessage  <code>pydantic-model</code>","text":"<p>               Bases: <code>BaseMessage</code></p> <p>Input message from the user. This class is used to create the input message from the user.</p>"},{"location":"core/session.html#director.core.session.InputMessage.publish","title":"publish","text":"<pre><code>publish()\n</code></pre> <p>Store the message in the database. for conversation history.</p> Source code in <code>backend/director/core/session.py</code> <pre><code>def publish(self):\n    \"\"\"Store the message in the database. for conversation history.\"\"\"\n    self.db.add_or_update_msg_to_conv(**self.model_dump(exclude={\"db\"}))\n</code></pre>"},{"location":"core/session.html#output-message","title":"Output Message","text":""},{"location":"core/session.html#director.core.session.OutputMessage","title":"director.core.session.OutputMessage  <code>pydantic-model</code>","text":"<p>               Bases: <code>BaseMessage</code></p> <p>Output message from the director. This class is used to create the output message from the director.</p>"},{"location":"core/session.html#director.core.session.OutputMessage.update_status","title":"update_status","text":"<pre><code>update_status(status)\n</code></pre> <p>Update the status of the message and publish the message to the socket. for loading state.</p> Source code in <code>backend/director/core/session.py</code> <pre><code>def update_status(self, status: MsgStatus):\n    \"\"\"Update the status of the message and publish the message to the socket. for loading state.\"\"\"\n    self.status = status\n    self._publish()\n</code></pre>"},{"location":"core/session.html#director.core.session.OutputMessage.push_update","title":"push_update","text":"<pre><code>push_update()\n</code></pre> <p>Publish the message to the socket.</p> Source code in <code>backend/director/core/session.py</code> <pre><code>def push_update(self):\n    \"\"\"Publish the message to the socket.\"\"\"\n    try:\n        self._publish()\n    except Exception as e:\n        print(f\"Error in emitting message: {str(e)}\")\n</code></pre>"},{"location":"core/session.html#director.core.session.OutputMessage.publish","title":"publish","text":"<pre><code>publish()\n</code></pre> <p>Store the message in the database. for conversation history and publish the message to the socket.</p> Source code in <code>backend/director/core/session.py</code> <pre><code>def publish(self):\n    \"\"\"Store the message in the database. for conversation history and publish the message to the socket.\"\"\"\n    self._publish()\n</code></pre>"},{"location":"core/session.html#context-message","title":"Context Message","text":""},{"location":"core/session.html#director.core.session.ContextMessage","title":"director.core.session.ContextMessage  <code>pydantic-model</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Context message class. This class is used to create the context message for the reasoning context.</p>"},{"location":"core/session.html#director.core.session.ContextMessage.to_llm_msg","title":"to_llm_msg","text":"<pre><code>to_llm_msg()\n</code></pre> <p>Convert the context message to the llm message.</p> Source code in <code>backend/director/core/session.py</code> <pre><code>def to_llm_msg(self):\n    \"\"\"Convert the context message to the llm message.\"\"\"\n    msg = {\n        \"role\": self.role,\n        \"content\": self.content,\n    }\n    if self.role == RoleTypes.system:\n        return msg\n\n    if self.role == RoleTypes.user:\n        return format_user_message(msg)\n\n    if self.role == RoleTypes.assistant:\n        if self.tool_calls:\n            msg[\"tool_calls\"] = self.tool_calls\n        if not self.content:\n            msg[\"content\"] = []\n        return msg\n\n    if self.role == RoleTypes.tool:\n        msg[\"tool_call_id\"] = self.tool_call_id\n        return msg\n</code></pre>"},{"location":"core/session.html#director.core.session.ContextMessage.from_json","title":"from_json  <code>classmethod</code>","text":"<pre><code>from_json(json_data)\n</code></pre> <p>Create the context message from the json data.</p> Source code in <code>backend/director/core/session.py</code> <pre><code>@classmethod\ndef from_json(cls, json_data):\n    \"\"\"Create the context message from the json data.\"\"\"\n    return cls(**json_data)\n</code></pre>"},{"location":"core/session.html#session_1","title":"Session","text":""},{"location":"core/session.html#director.core.session.Session","title":"director.core.session.Session","text":"<pre><code>Session(\n    db,\n    session_id=\"\",\n    conv_id=\"\",\n    collection_id=None,\n    video_id=None,\n    **kwargs\n)\n</code></pre> <p>A class to manage and interact with a session in the database. The session is used to store the conversation and reasoning context messages.</p> Source code in <code>backend/director/core/session.py</code> <pre><code>def __init__(\n    self,\n    db: BaseDB,\n    session_id: str = \"\",\n    conv_id: str = \"\",\n    collection_id: str = None,\n    video_id: str = None,\n    **kwargs,\n):\n    self.db = db\n    self.session_id = session_id\n    self.conv_id = conv_id\n    self.conversations = []\n    self.video_id = video_id\n    self.collection_id = collection_id\n    self.reasoning_context = []\n    self.state = {}\n    self.output_message = OutputMessage(\n        db=self.db, session_id=self.session_id, conv_id=self.conv_id\n    )\n\n    self.get_context_messages()\n</code></pre>"},{"location":"core/session.html#director.core.session.Session.save_context_messages","title":"save_context_messages","text":"<pre><code>save_context_messages()\n</code></pre> <p>Save the reasoning context messages to the database.</p> Source code in <code>backend/director/core/session.py</code> <pre><code>def save_context_messages(self):\n    \"\"\"Save the reasoning context messages to the database.\"\"\"\n    context = {\n        \"reasoning\": [message.to_llm_msg() for message in self.reasoning_context],\n    }\n    self.db.add_or_update_context_msg(self.session_id, context)\n</code></pre>"},{"location":"core/session.html#director.core.session.Session.get_context_messages","title":"get_context_messages","text":"<pre><code>get_context_messages()\n</code></pre> <p>Get the reasoning context messages from the database.</p> Source code in <code>backend/director/core/session.py</code> <pre><code>def get_context_messages(self):\n    \"\"\"Get the reasoning context messages from the database.\"\"\"\n    if not self.reasoning_context:\n        context = self.db.get_context_messages(self.session_id)\n        self.reasoning_context = [\n            ContextMessage.from_json(message)\n            for message in context.get(\"reasoning\", [])\n        ]\n\n    return self.reasoning_context\n</code></pre>"},{"location":"core/session.html#director.core.session.Session.create","title":"create","text":"<pre><code>create()\n</code></pre> <p>Create a new session in the database.</p> Source code in <code>backend/director/core/session.py</code> <pre><code>def create(self):\n    \"\"\"Create a new session in the database.\"\"\"\n    self.db.create_session(**self.__dict__)\n</code></pre>"},{"location":"core/session.html#director.core.session.Session.new_message","title":"new_message","text":"<pre><code>new_message(msg_type=MsgType.output, **kwargs)\n</code></pre> <p>Returns a new input/output message object.</p> <p>Parameters:</p> Name Type Description Default <code>msg_type</code> <code>MsgType</code> <p>The type of the message, input or output.</p> <code>output</code> <code>kwargs</code> <code>dict</code> <p>The message attributes.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Union[InputMessage, OutputMessage]</code> <p>The input/output message object.</p> Source code in <code>backend/director/core/session.py</code> <pre><code>def new_message(\n    self, msg_type: MsgType = MsgType.output, **kwargs\n) -&gt; Union[InputMessage, OutputMessage]:\n    \"\"\"Returns a new input/output message object.\n\n    :param MsgType msg_type: The type of the message, input or output.\n    :param dict kwargs: The message attributes.\n    :return: The input/output message object.\n    \"\"\"\n    if msg_type == MsgType.input:\n        return InputMessage(\n            db=self.db,\n            session_id=self.session_id,\n            conv_id=self.conv_id,\n            **kwargs,\n        )\n    return OutputMessage(\n        db=self.db,\n        session_id=self.session_id,\n        conv_id=self.conv_id,\n        **kwargs,\n    )\n</code></pre>"},{"location":"core/session.html#director.core.session.Session.get","title":"get","text":"<pre><code>get()\n</code></pre> <p>Get the session from the database.</p> Source code in <code>backend/director/core/session.py</code> <pre><code>def get(self):\n    \"\"\"Get the session from the database.\"\"\"\n    session = self.db.get_session(self.session_id)\n    conversation = self.db.get_conversations(self.session_id)\n    session[\"conversation\"] = conversation\n    return session\n</code></pre>"},{"location":"core/session.html#director.core.session.Session.get_all","title":"get_all","text":"<pre><code>get_all()\n</code></pre> <p>Get all the sessions from the database.</p> Source code in <code>backend/director/core/session.py</code> <pre><code>def get_all(self):\n    \"\"\"Get all the sessions from the database.\"\"\"\n    return self.db.get_sessions()\n</code></pre>"},{"location":"core/session.html#director.core.session.Session.delete","title":"delete","text":"<pre><code>delete()\n</code></pre> <p>Delete the session from the database.</p> Source code in <code>backend/director/core/session.py</code> <pre><code>def delete(self):\n    \"\"\"Delete the session from the database.\"\"\"\n    return self.db.delete_session(self.session_id)\n</code></pre>"},{"location":"core/session.html#director.core.session.Session.emit_event","title":"emit_event","text":"<pre><code>emit_event(event, namespace='/chat')\n</code></pre> <p>Emits a structured WebSocket event to notify all clients about updates.</p> Source code in <code>backend/director/core/session.py</code> <pre><code>def emit_event(self, event: BaseEvent, namespace=\"/chat\"):\n    \"\"\"Emits a structured WebSocket event to notify all clients about updates.\"\"\"\n\n    event_payload = event.model_dump()\n\n    try:\n        emit(\"event\", event_payload, namespace=namespace)\n    except Exception:\n        pass\n</code></pre>"},{"location":"database/interface.html","title":"Interface","text":""},{"location":"database/interface.html#database-interface","title":"Database Interface","text":"<p>Base DB is the base class for all databases. It provides a common interface for all databases to follow.</p>"},{"location":"database/interface.html#base-db","title":"Base DB","text":""},{"location":"database/interface.html#director.db.base.BaseDB","title":"director.db.base.BaseDB","text":"<p>               Bases: <code>ABC</code></p> <p>Interface for all databases. It provides a common interface for all databases to follow.</p>"},{"location":"database/interface.html#director.db.base.BaseDB.create_session","title":"create_session  <code>abstractmethod</code>","text":"<pre><code>create_session(\n    session_id, video_id=None, collection_id=None\n)\n</code></pre> <p>Create a new session.</p> Source code in <code>backend/director/db/base.py</code> <pre><code>@abstractmethod\ndef create_session(\n    self, session_id: str, video_id: str = None, collection_id: str = None\n) -&gt; None:\n    \"\"\"Create a new session.\"\"\"\n    pass\n</code></pre>"},{"location":"database/interface.html#director.db.base.BaseDB.get_session","title":"get_session  <code>abstractmethod</code>","text":"<pre><code>get_session(session_id)\n</code></pre> <p>Get a session by session_id.</p> Source code in <code>backend/director/db/base.py</code> <pre><code>@abstractmethod\ndef get_session(self, session_id: str) -&gt; dict:\n    \"\"\"Get a session by session_id.\"\"\"\n    pass\n</code></pre>"},{"location":"database/interface.html#director.db.base.BaseDB.get_sessions","title":"get_sessions  <code>abstractmethod</code>","text":"<pre><code>get_sessions()\n</code></pre> <p>Get all sessions.</p> Source code in <code>backend/director/db/base.py</code> <pre><code>@abstractmethod\ndef get_sessions(self) -&gt; list:\n    \"\"\"Get all sessions.\"\"\"\n    pass\n</code></pre>"},{"location":"database/interface.html#director.db.base.BaseDB.add_or_update_msg_to_conv","title":"add_or_update_msg_to_conv  <code>abstractmethod</code>","text":"<pre><code>add_or_update_msg_to_conv()\n</code></pre> <p>Add a new message (input or output) to the conversation.</p> Source code in <code>backend/director/db/base.py</code> <pre><code>@abstractmethod\ndef add_or_update_msg_to_conv() -&gt; None:\n    \"\"\"Add a new message (input or output) to the conversation.\"\"\"\n    pass\n</code></pre>"},{"location":"database/interface.html#director.db.base.BaseDB.get_conversations","title":"get_conversations  <code>abstractmethod</code>","text":"<pre><code>get_conversations(session_id)\n</code></pre> <p>Get all conversations for a given session.</p> Source code in <code>backend/director/db/base.py</code> <pre><code>@abstractmethod\ndef get_conversations(self, session_id: str) -&gt; list:\n    \"\"\"Get all conversations for a given session.\"\"\"\n    pass\n</code></pre>"},{"location":"database/interface.html#director.db.base.BaseDB.get_context_messages","title":"get_context_messages  <code>abstractmethod</code>","text":"<pre><code>get_context_messages(session_id)\n</code></pre> <p>Get context messages for a session.</p> Source code in <code>backend/director/db/base.py</code> <pre><code>@abstractmethod\ndef get_context_messages(self, session_id: str) -&gt; list:\n    \"\"\"Get context messages for a session.\"\"\"\n    pass\n</code></pre>"},{"location":"database/interface.html#director.db.base.BaseDB.add_or_update_context_msg","title":"add_or_update_context_msg  <code>abstractmethod</code>","text":"<pre><code>add_or_update_context_msg(session_id, context_messages)\n</code></pre> <p>Update context messages for a session.</p> Source code in <code>backend/director/db/base.py</code> <pre><code>@abstractmethod\ndef add_or_update_context_msg(\n    self, session_id: str, context_messages: list\n) -&gt; None:\n    \"\"\"Update context messages for a session.\"\"\"\n    pass\n</code></pre>"},{"location":"database/interface.html#director.db.base.BaseDB.health_check","title":"health_check  <code>abstractmethod</code>","text":"<pre><code>health_check()\n</code></pre> <p>Check if the database is healthy.</p> Source code in <code>backend/director/db/base.py</code> <pre><code>@abstractmethod\ndef health_check(self) -&gt; bool:\n    \"\"\"Check if the database is healthy.\"\"\"\n    pass\n</code></pre>"},{"location":"database/sqlite.html","title":"SQLite","text":"<p>SQLite DB is the database used by the agents and tools. It is used to store the conversations and context messages.</p>"},{"location":"database/sqlite.html#initialize-sqlite","title":"Initialize SQLite","text":"<p>Create a new SQLite database and tables.</p> <pre><code>make init-sqlite-db\n</code></pre>"},{"location":"database/sqlite.html#sqlite-interface","title":"SQLite Interface","text":""},{"location":"database/sqlite.html#director.db.sqlite.db.SQLiteDB","title":"director.db.sqlite.db.SQLiteDB","text":"<pre><code>SQLiteDB(db_path=None)\n</code></pre> <p>               Bases: <code>BaseDB</code></p> <p>Parameters:</p> Name Type Description Default <code>db_path</code> <code>str</code> <p>Path to the SQLite database file.</p> <code>None</code> Source code in <code>backend/director/db/sqlite/db.py</code> <pre><code>def __init__(self, db_path: str = None):\n    \"\"\"\n    :param db_path: Path to the SQLite database file.\n    \"\"\"\n    self.db_type = DBType.SQLITE\n    if db_path is None:\n        self.db_path = os.getenv(\"SQLITE_DB_PATH\", \"director.db\")\n    else:\n        self.db_path = db_path\n    self.conn = sqlite3.connect(self.db_path, check_same_thread=True)\n    self.conn.row_factory = sqlite3.Row\n    self.cursor = self.conn.cursor()\n    logger.info(\"Connected to SQLite DB...\")\n</code></pre>"},{"location":"database/sqlite.html#director.db.sqlite.db.SQLiteDB.create_session","title":"create_session","text":"<pre><code>create_session(\n    session_id,\n    video_id,\n    collection_id,\n    created_at=None,\n    updated_at=None,\n    metadata={},\n    **kwargs\n)\n</code></pre> <p>Create a new session.</p> <p>Parameters:</p> Name Type Description Default <code>session_id</code> <code>str</code> <p>Unique session ID.</p> required <code>video_id</code> <code>str</code> <p>ID of the video associated with the session.</p> required <code>collection_id</code> <code>str</code> <p>ID of the collection associated with the session.</p> required <code>created_at</code> <code>int</code> <p>Timestamp when the session was created.</p> <code>None</code> <code>updated_at</code> <code>int</code> <p>Timestamp when the session was last updated.</p> <code>None</code> <code>metadata</code> <code>dict</code> <p>Additional metadata for the session.</p> <code>{}</code> Source code in <code>backend/director/db/sqlite/db.py</code> <pre><code>def create_session(\n    self,\n    session_id: str,\n    video_id: str,\n    collection_id: str,\n    created_at: int = None,\n    updated_at: int = None,\n    metadata: dict = {},\n    **kwargs,\n) -&gt; None:\n    \"\"\"Create a new session.\n\n    :param session_id: Unique session ID.\n    :param video_id: ID of the video associated with the session.\n    :param collection_id: ID of the collection associated with the session.\n    :param created_at: Timestamp when the session was created.\n    :param updated_at: Timestamp when the session was last updated.\n    :param metadata: Additional metadata for the session.\n    \"\"\"\n    created_at = created_at or int(time.time())\n    updated_at = updated_at or int(time.time())\n\n    self.cursor.execute(\n        \"\"\"\n    INSERT OR IGNORE INTO sessions (session_id, video_id, collection_id, created_at, updated_at, metadata)\n    VALUES (?, ?, ?, ?, ?, ?)\n    \"\"\",\n        (\n            session_id,\n            video_id,\n            collection_id,\n            created_at,\n            updated_at,\n            json.dumps(metadata),\n        ),\n    )\n    self.conn.commit()\n</code></pre>"},{"location":"database/sqlite.html#director.db.sqlite.db.SQLiteDB.get_session","title":"get_session","text":"<pre><code>get_session(session_id)\n</code></pre> <p>Get a session by session_id.</p> <p>Parameters:</p> Name Type Description Default <code>session_id</code> <code>str</code> <p>Unique session ID.</p> required <p>Returns:</p> Type Description <code>dict</code> <p>Session data as a dictionary.</p> Source code in <code>backend/director/db/sqlite/db.py</code> <pre><code>def get_session(self, session_id: str) -&gt; dict:\n    \"\"\"Get a session by session_id.\n\n    :param session_id: Unique session ID.\n    :return: Session data as a dictionary.\n    :rtype: dict\n    \"\"\"\n    self.cursor.execute(\n        \"SELECT * FROM sessions WHERE session_id = ?\", (session_id,)\n    )\n    row = self.cursor.fetchone()\n    if row is not None:\n        session = dict(row)  # Convert sqlite3.Row to dictionary\n        session[\"metadata\"] = json.loads(session[\"metadata\"])\n        return session\n\n    else:\n        return {}  # Return an empty dictionary if no data found\n</code></pre>"},{"location":"database/sqlite.html#director.db.sqlite.db.SQLiteDB.get_sessions","title":"get_sessions","text":"<pre><code>get_sessions()\n</code></pre> <p>Get all sessions.</p> <p>Returns:</p> Type Description <code>list</code> <p>List of all sessions.</p> Source code in <code>backend/director/db/sqlite/db.py</code> <pre><code>def get_sessions(self) -&gt; list:\n    \"\"\"Get all sessions.\n\n    :return: List of all sessions.\n    :rtype: list\n    \"\"\"\n    self.cursor.execute(\"SELECT * FROM sessions ORDER BY updated_at DESC\")\n    row = self.cursor.fetchall()\n    sessions = [dict(r) for r in row]\n    for s in sessions:\n        s[\"metadata\"] = json.loads(s[\"metadata\"])\n    return sessions\n</code></pre>"},{"location":"database/sqlite.html#director.db.sqlite.db.SQLiteDB.add_or_update_msg_to_conv","title":"add_or_update_msg_to_conv","text":"<pre><code>add_or_update_msg_to_conv(\n    session_id,\n    conv_id,\n    msg_id,\n    msg_type,\n    agents,\n    actions,\n    content,\n    status=None,\n    created_at=None,\n    updated_at=None,\n    metadata={},\n    **kwargs\n)\n</code></pre> <p>Add a new message (input or output) to the conversation.</p> <p>Parameters:</p> Name Type Description Default <code>session_id</code> <code>str</code> <p>Unique session ID.</p> required <code>conv_id</code> <code>str</code> <p>Unique conversation ID.</p> required <code>msg_id</code> <code>str</code> <p>Unique message ID.</p> required <code>msg_type</code> <code>str</code> <p>Type of message (input or output).</p> required <code>agents</code> <code>list</code> <p>List of agents involved in the conversation.</p> required <code>actions</code> <code>list</code> <p>List of actions taken by the agents.</p> required <code>content</code> <code>list</code> <p>List of message content.</p> required <code>status</code> <code>str</code> <p>Status of the message.</p> <code>None</code> <code>created_at</code> <code>int</code> <p>Timestamp when the message was created.</p> <code>None</code> <code>updated_at</code> <code>int</code> <p>Timestamp when the message was last updated.</p> <code>None</code> <code>metadata</code> <code>dict</code> <p>Additional metadata for the message.</p> <code>{}</code> Source code in <code>backend/director/db/sqlite/db.py</code> <pre><code>def add_or_update_msg_to_conv(\n    self,\n    session_id: str,\n    conv_id: str,\n    msg_id: str,\n    msg_type: str,\n    agents: List[str],\n    actions: List[str],\n    content: List[dict],\n    status: str = None,\n    created_at: int = None,\n    updated_at: int = None,\n    metadata: dict = {},\n    **kwargs,\n) -&gt; None:\n    \"\"\"Add a new message (input or output) to the conversation.\n\n    :param str session_id: Unique session ID.\n    :param str conv_id: Unique conversation ID.\n    :param str msg_id: Unique message ID.\n    :param str msg_type: Type of message (input or output).\n    :param list agents: List of agents involved in the conversation.\n    :param list actions: List of actions taken by the agents.\n    :param list content: List of message content.\n    :param str status: Status of the message.\n    :param int created_at: Timestamp when the message was created.\n    :param int updated_at: Timestamp when the message was last updated.\n    :param dict metadata: Additional metadata for the message.\n    \"\"\"\n    created_at = created_at or int(time.time())\n    updated_at = updated_at or int(time.time())\n\n    self.cursor.execute(\n        \"\"\"\n    INSERT OR REPLACE INTO conversations (session_id, conv_id, msg_id, msg_type, agents, actions, content, status, created_at, updated_at, metadata)\n    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n    \"\"\",\n        (\n            session_id,\n            conv_id,\n            msg_id,\n            msg_type,\n            json.dumps(agents),\n            json.dumps(actions),\n            json.dumps(content),\n            status,\n            created_at,\n            updated_at,\n            json.dumps(metadata),\n        ),\n    )\n    self.conn.commit()\n</code></pre>"},{"location":"database/sqlite.html#director.db.sqlite.db.SQLiteDB.get_context_messages","title":"get_context_messages","text":"<pre><code>get_context_messages(session_id)\n</code></pre> <p>Get context messages for a session.</p> <p>Parameters:</p> Name Type Description Default <code>session_id</code> <code>str</code> <p>Unique session ID.</p> required <p>Returns:</p> Type Description <code>list</code> <p>List of context messages.</p> Source code in <code>backend/director/db/sqlite/db.py</code> <pre><code>def get_context_messages(self, session_id: str) -&gt; list:\n    \"\"\"Get context messages for a session.\n\n    :param str session_id: Unique session ID.\n    :return: List of context messages.\n    :rtype: list\n    \"\"\"\n    self.cursor.execute(\n        \"SELECT context_data FROM context_messages WHERE session_id = ?\",\n        (session_id,),\n    )\n    result = self.cursor.fetchone()\n    return json.loads(result[0]) if result else {}\n</code></pre>"},{"location":"database/sqlite.html#director.db.sqlite.db.SQLiteDB.add_or_update_context_msg","title":"add_or_update_context_msg","text":"<pre><code>add_or_update_context_msg(\n    session_id,\n    context_messages,\n    created_at=None,\n    updated_at=None,\n    metadata={},\n    **kwargs\n)\n</code></pre> <p>Update context messages for a session.</p> <p>Parameters:</p> Name Type Description Default <code>session_id</code> <code>str</code> <p>Unique session ID.</p> required <code>context_messages</code> <code>List</code> <p>List of context messages.</p> required <code>created_at</code> <code>int</code> <p>Timestamp when the context messages were created.</p> <code>None</code> <code>updated_at</code> <code>int</code> <p>Timestamp when the context messages were last updated.</p> <code>None</code> <code>metadata</code> <code>dict</code> <p>Additional metadata for the context messages.</p> <code>{}</code> Source code in <code>backend/director/db/sqlite/db.py</code> <pre><code>def add_or_update_context_msg(\n    self,\n    session_id: str,\n    context_messages: list,\n    created_at: int = None,\n    updated_at: int = None,\n    metadata: dict = {},\n    **kwargs,\n) -&gt; None:\n    \"\"\"Update context messages for a session.\n\n    :param str session_id: Unique session ID.\n    :param List context_messages: List of context messages.\n    :param int created_at: Timestamp when the context messages were created.\n    :param int updated_at: Timestamp when the context messages were last updated.\n    :param dict metadata: Additional metadata for the context messages.\n    \"\"\"\n    created_at = created_at or int(time.time())\n    updated_at = updated_at or int(time.time())\n\n    self.cursor.execute(\n        \"\"\"\n    INSERT OR REPLACE INTO context_messages (context_data, session_id, created_at, updated_at, metadata)\n    VALUES (?, ?, ?, ?, ?)\n    \"\"\",\n        (\n            json.dumps(context_messages),\n            session_id,\n            created_at,\n            updated_at,\n            json.dumps(metadata),\n        ),\n    )\n    self.conn.commit()\n</code></pre>"},{"location":"database/sqlite.html#director.db.sqlite.db.SQLiteDB.delete_conversation","title":"delete_conversation","text":"<pre><code>delete_conversation(session_id)\n</code></pre> <p>Delete all conversations for a given session.</p> <p>Parameters:</p> Name Type Description Default <code>session_id</code> <code>str</code> <p>Unique session ID.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if conversations were deleted, False otherwise.</p> Source code in <code>backend/director/db/sqlite/db.py</code> <pre><code>def delete_conversation(self, session_id: str) -&gt; bool:\n    \"\"\"Delete all conversations for a given session.\n\n    :param str session_id: Unique session ID.\n    :return: True if conversations were deleted, False otherwise.\n    \"\"\"\n    self.cursor.execute(\n        \"DELETE FROM conversations WHERE session_id = ?\", (session_id,)\n    )\n    self.conn.commit()\n    return self.cursor.rowcount &gt; 0\n</code></pre>"},{"location":"database/sqlite.html#director.db.sqlite.db.SQLiteDB.delete_context","title":"delete_context","text":"<pre><code>delete_context(session_id)\n</code></pre> <p>Delete context messages for a given session.</p> <p>Parameters:</p> Name Type Description Default <code>session_id</code> <code>str</code> <p>Unique session ID.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if context messages were deleted, False otherwise.</p> Source code in <code>backend/director/db/sqlite/db.py</code> <pre><code>def delete_context(self, session_id: str) -&gt; bool:\n    \"\"\"Delete context messages for a given session.\n\n    :param str session_id: Unique session ID.\n    :return: True if context messages were deleted, False otherwise.\n    \"\"\"\n    self.cursor.execute(\n        \"DELETE FROM context_messages WHERE session_id = ?\", (session_id,)\n    )\n    self.conn.commit()\n    return self.cursor.rowcount &gt; 0\n</code></pre>"},{"location":"database/sqlite.html#director.db.sqlite.db.SQLiteDB.delete_session","title":"delete_session","text":"<pre><code>delete_session(session_id)\n</code></pre> <p>Delete a session and all its associated data.</p> <p>Parameters:</p> Name Type Description Default <code>session_id</code> <code>str</code> <p>Unique session ID.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the session was deleted, False otherwise.</p> Source code in <code>backend/director/db/sqlite/db.py</code> <pre><code>def delete_session(self, session_id: str) -&gt; bool:\n    \"\"\"Delete a session and all its associated data.\n\n    :param str session_id: Unique session ID.\n    :return: True if the session was deleted, False otherwise.\n    \"\"\"\n    failed_components = []\n    if not self.delete_conversation(session_id):\n        failed_components.append(\"conversation\")\n    if not self.delete_context(session_id):\n        failed_components.append(\"context\")\n    self.cursor.execute(\"DELETE FROM sessions WHERE session_id = ?\", (session_id,))\n    self.conn.commit()\n    if not self.cursor.rowcount &gt; 0:\n        failed_components.append(\"session\")\n    success = len(failed_components) &lt; 3\n    return success, failed_components\n</code></pre>"},{"location":"database/sqlite.html#director.db.sqlite.db.SQLiteDB.health_check","title":"health_check","text":"<pre><code>health_check()\n</code></pre> <p>Check if the SQLite database is healthy and the necessary tables exist. If not, create them.</p> Source code in <code>backend/director/db/sqlite/db.py</code> <pre><code>def health_check(self) -&gt; bool:\n    \"\"\"Check if the SQLite database is healthy and the necessary tables exist. If not, create them.\"\"\"\n    try:\n        query = \"\"\"\n            SELECT COUNT(name)\n            FROM sqlite_master\n            WHERE type='table'\n            AND name IN ('sessions', 'conversations', 'context_messages');\n        \"\"\"\n        self.cursor.execute(query)\n        table_count = self.cursor.fetchone()[0]\n        if table_count &lt; 3:\n            logger.info(\"Tables not found. Initializing SQLite DB...\")\n            initialize_sqlite(self.db_path)\n        return True\n\n    except Exception as e:\n        logger.exception(f\"SQLite health check failed: {e}\")\n        return False\n</code></pre>"},{"location":"get_started/contributing.html","title":"Guidlines for contributing to the project","text":"<p>We welcome contributions to the Director from developers, researchers, and enthusiasts interested in video processing, AI, and related fields. This document outlines the guidelines for contributing to the project, including the process for submitting issues, feature requests, and pull requests.</p> <p>Any contributions you make are greatly appreciated. Here's the process:</p> <ol> <li>Fork the Project</li> <li>Create your Feature Branch (<code>git checkout -b feature/AmazingFeature</code>)</li> <li>Commit your Changes (<code>git commit -m 'Add some AmazingFeature'</code>)</li> <li>Push to the Branch (<code>git push origin feature/AmazingFeature</code>)</li> <li>Open a Pull Request</li> </ol>"},{"location":"get_started/install.html","title":"Getting Started","text":""},{"location":"get_started/install.html#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.9 or higher</li> <li>Node.js 22.8.0 or higher</li> <li>npm</li> </ul>"},{"location":"get_started/install.html#installation","title":"Installation","text":"<ol> <li>Clone the repository:</li> </ol> <pre><code>git clone https://github.com/video-db/Director.git\ncd Director\n</code></pre> <ol> <li>Set up the environment:</li> </ol> <pre><code>./setup.sh\n</code></pre> <p>This script will: - Install nvm (Node Version Manager) if not already installed - Install Node.js 22.8.0 using nvm - Install Python and pip - Set up virtual environments for both frontend and backend - Install dependencies for both frontend and backend</p> <p>Supported platforms: - Mac - Linux</p> <ol> <li>Configure the environment variables:</li> </ol> <pre><code>cp backend/.env.example backend/.env\ncp frontend/.env.example frontend/.env\n</code></pre> <p>Edit the <code>.env</code> files to add your API keys and other configuration options.</p> <p>[TODO]: Add all supported variables or point to documentation where we have given the list.</p> <ol> <li>Initialize and configuring the Database</li> </ol> <p>For SQLite (default): <pre><code>make init-sqlite-db\n</code></pre></p> <p>This command will initialize the SQLite DB file in the <code>backend</code> directory. No additional configuration is required for SQLite.</p> <p>For other databases, follow the documentation here.</p>"},{"location":"get_started/install.html#project-structure","title":"Project Structure","text":"<ul> <li><code>backend/</code>: Contains the Flask backend application</li> <li><code>frontend/</code>: Contains the Vue 3 frontend application</li> <li><code>docs/</code>: Project documentation</li> <li><code>infra/</code>: Infrastructure-related files</li> </ul>"},{"location":"get_started/install.html#running-the-application","title":"Running the Application","text":"<p>To start both the backend and frontend servers:</p> <pre><code>make run\n</code></pre> <p>This will start the backend server on <code>http://127.0.0.1:8000</code> and the frontend server on <code>http://127.0.0.1:8080</code>.</p> <p>To run only the backend server:</p> <pre><code>make run-be\n</code></pre> <p>To just run the frontend development server:</p> <pre><code>make run-fe\n</code></pre>"},{"location":"get_started/railway.html","title":"Railway","text":"<p>Note</p> <p>You need to be connected to GitHub account in https://railway.app/account/plans to perform the deployment.</p>"},{"location":"get_started/railway.html#deployment-instructions-via-railway-template","title":"Deployment Instructions via Railway Template","text":"<ol> <li>Go to the Director's Railway Template.</li> <li>Click Deploy Now.</li> <li>Set the frontend environment variable <code>VITE_APP_BACKEND_URL</code> with a placeholder.</li> <li>For the backend, configure the required environment variables <code>VIDEO_DB_API_KEY</code> and <code>OPENAI_API_KEY</code>. Optionally, you can configure additional environment variables as needed.</li> <li>Click Deploy.</li> <li>Once both services are deployed successfully, click on the backend service and copy the public URL (e.g., <code>https://backend-production-xxxx.up.railway.app</code>).</li> <li>Update the frontend's <code>VITE_APP_BACKEND_URL</code> variable with the copied backend URL.</li> <li>After updating the <code>VITE_APP_BACKEND_URL</code> variable, a Deploy option will appear. Click it to re-deploy the frontend.</li> <li>Once deployment is complete, access the application through the frontend's public URL, such as <code>https://frontend-production-xxxx.up.railway.app</code>.</li> </ol>"},{"location":"get_started/railway.html#deployment-instructions-via-railway-cli","title":"Deployment Instructions via Railway CLI","text":"<ol> <li>Clone the Director repository to your local machine:     <pre><code>git clone https://github.com/video-db/Director\n</code></pre></li> <li>Change the directory to the cloned repository:     <pre><code>cd Director\n</code></pre></li> <li>Install the Railway CLI.</li> <li>Navigate to the Railway Dashboard and create an empty project.</li> <li>Add two empty services to the project, and rename them as backend and frontend.</li> <li>Log in to Railway via the CLI:     <pre><code>railway login\n</code></pre></li> </ol>"},{"location":"get_started/railway.html#deploy-the-backend-service","title":"Deploy the backend service:","text":"<ul> <li>Navigate to the backend service directory</li> <li>Link your project and the backend service     <pre><code>railway link \n</code></pre></li> <li>Deploy the backend service     <pre><code>railway up\n</code></pre></li> </ul>"},{"location":"get_started/railway.html#deploy-the-frontend-service","title":"Deploy the frontend service:","text":"<ul> <li>Navigate to the frontend service directory</li> <li>Link your project and the frontend service     <pre><code>railway link \n</code></pre></li> <li>Deploy the frontend service     <pre><code>railway up\n</code></pre></li> </ul>"},{"location":"get_started/railway.html#backend-configuration","title":"Backend Configuration","text":"<ul> <li> <p>After deployment, go to the Railway project dashboard, and under the backend service, update the environment variables:     <pre><code>VIDEO_DB_API_KEY=\"your_video_db_api_key\"\n</code></pre></p> </li> <li> <p>Go to Settings \u2192 Networking \u2192 Public Networking, generate a domain, and copy the domain. You will need to use this domain in the frontend service configuration.</p> </li> </ul>"},{"location":"get_started/railway.html#frontend-configuration","title":"Frontend Configuration","text":"<ul> <li> <p>In the frontend service , update the following environment variable:     <pre><code>VITE_APP_BACKEND_URL=\"deployed_backend_service_public_url\"\n</code></pre></p> </li> <li> <p>After deployment, generate a domain and navigate to the frontend service URL (which can be found in Settings \u2192 Networking \u2192 Public Networking) in your web browser to access the Director application.</p> </li> </ul>"},{"location":"get_started/render.html","title":"Render","text":""},{"location":"get_started/render.html#deployment-instructions","title":"Deployment Instructions","text":"<ol> <li>Go to the Render dashboard.</li> <li>Click Add New Blueprint Instance by visiting this link.</li> <li>Add the public Director Git repository: Director Repository. Alternatively, you can fork the repository and connect your fork to your Railway account.</li> <li>Set a name for the blueprint and deploy it. This will deploy both the frontend and backend services.</li> </ol>"},{"location":"get_started/render.html#backend-configuration","title":"Backend Configuration","text":"<p>After deployment, update the backend environment variables:     <pre><code>VIDEO_DB_API_KEY=\"your_video_db_api_key\"\n</code></pre></p>"},{"location":"get_started/render.html#frontend-configuration","title":"Frontend Configuration","text":"<p>Next, update the frontend environment variables:     <pre><code>VITE_APP_BACKEND_URL=\"deployed_backend_service_public_url\"\n</code></pre></p> <p>Once the deployment is complete, navigate to the frontend service URL in your web browser to access the Director application.</p>"},{"location":"llm/anthropic.html","title":"AnthropicAI","text":""},{"location":"llm/anthropic.html#anthropicai","title":"AnthropicAI","text":"<p>AnthropicAI extends the base LLM and implements the Anthropic API.</p>"},{"location":"llm/anthropic.html#anthropicai-config","title":"AnthropicAI Config","text":"<p>AnthropicAI Config is the configuration object for AnthropicAI. It is used to configure AnthropicAI and is passed to AnthropicAI when it is created.</p>"},{"location":"llm/anthropic.html#director.llm.anthropic.AnthropicAIConfig","title":"director.llm.anthropic.AnthropicAIConfig","text":"<p>               Bases: <code>BaseLLMConfig</code></p> <p>AnthropicAI Config</p>"},{"location":"llm/anthropic.html#anthropicai-interface","title":"AnthropicAI Interface","text":"<p>AnthropicAI is the LLM used by the agents and tools. It is used to generate responses to messages.</p>"},{"location":"llm/anthropic.html#director.llm.anthropic.AnthropicAI","title":"director.llm.anthropic.AnthropicAI","text":"<pre><code>AnthropicAI(config=None)\n</code></pre> <p>               Bases: <code>BaseLLM</code></p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>AnthropicAIConfig</code> <p>AnthropicAI Config</p> <code>None</code> Source code in <code>backend/director/llm/anthropic.py</code> <pre><code>def __init__(self, config: AnthropicAIConfig = None):\n    \"\"\"\n    :param config: AnthropicAI Config\n    \"\"\"\n    if config is None:\n        config = AnthropicAIConfig()\n    super().__init__(config=config)\n    try:\n        import anthropic\n    except ImportError:\n        raise ImportError(\"Please install Anthropic python library.\")\n\n    self.client = anthropic.Anthropic(api_key=self.api_key)\n</code></pre>"},{"location":"llm/anthropic.html#director.llm.anthropic.AnthropicAI._format_tools","title":"_format_tools","text":"<pre><code>_format_tools(tools)\n</code></pre> <p>Format the tools to the format that Anthropic expects.</p> <p>Example::</p> <pre><code>[\n    {\n        \"name\": \"get_weather\",\n        \"description\": \"Get the current weather in a given location\",\n        \"input_schema\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"location\": {\n                    \"type\": \"string\",\n                    \"description\": \"The city and state, e.g. San Francisco, CA\",\n                }\n            },\n            \"required\": [\"location\"],\n        },\n    }\n]\n</code></pre> Source code in <code>backend/director/llm/anthropic.py</code> <pre><code>def _format_tools(self, tools: list):\n    \"\"\"Format the tools to the format that Anthropic expects.\n\n    **Example**::\n\n        [\n            {\n                \"name\": \"get_weather\",\n                \"description\": \"Get the current weather in a given location\",\n                \"input_schema\": {\n                    \"type\": \"object\",\n                    \"properties\": {\n                        \"location\": {\n                            \"type\": \"string\",\n                            \"description\": \"The city and state, e.g. San Francisco, CA\",\n                        }\n                    },\n                    \"required\": [\"location\"],\n                },\n            }\n        ]\n    \"\"\"\n    formatted_tools = []\n    for tool in tools:\n        formatted_tools.append(\n            {\n                \"name\": tool[\"name\"],\n                \"description\": tool[\"description\"],\n                \"input_schema\": tool[\"parameters\"],\n            }\n        )\n    return formatted_tools\n</code></pre>"},{"location":"llm/anthropic.html#director.llm.anthropic.AnthropicAI.chat_completions","title":"chat_completions","text":"<pre><code>chat_completions(\n    messages, tools=[], stop=None, response_format=None\n)\n</code></pre> <p>Get completions for chat.</p> <p>tools docs: https://docs.anthropic.com/en/docs/build-with-claude/tool-use</p> Source code in <code>backend/director/llm/anthropic.py</code> <pre><code>def chat_completions(\n    self, messages: list, tools: list = [], stop=None, response_format=None\n):\n    \"\"\"Get completions for chat.\n\n    tools docs: https://docs.anthropic.com/en/docs/build-with-claude/tool-use\n    \"\"\"\n    system, messages = self._format_messages(messages)\n    params = {\n        \"model\": self.chat_model,\n        \"messages\": messages,\n        \"system\": system,\n        \"max_tokens\": self.max_tokens,\n    }\n    if tools:\n        params[\"tools\"] = self._format_tools(tools)\n\n    try:\n        response = self.client.messages.create(**params)\n    except Exception as e:\n        raise e\n        return LLMResponse(content=f\"Error: {e}\")\n\n    return LLMResponse(\n        content=response.content[0].text,\n        tool_calls=[\n            {\n                \"id\": response.content[1].id,\n                \"tool\": {\n                    \"name\": response.content[1].name,\n                    \"arguments\": response.content[1].input,\n                },\n                \"type\": response.content[1].type,\n            }\n        ]\n        if next(\n            (block for block in response.content if block.type == \"tool_use\"), None\n        )\n        is not None\n        else [],\n        finish_reason=response.stop_reason,\n        send_tokens=response.usage.input_tokens,\n        recv_tokens=response.usage.output_tokens,\n        total_tokens=(response.usage.input_tokens + response.usage.output_tokens),\n        status=LLMResponseStatus.SUCCESS,\n    )\n</code></pre>"},{"location":"llm/googleai.html","title":"GoogleAI","text":""},{"location":"llm/googleai.html#googleai","title":"GoogleAI","text":"<p>GoogleAI extends the Base LLM and implements the Google Gemini API.</p>"},{"location":"llm/googleai.html#googleai-config","title":"GoogleAI Config","text":"<p>GoogleAI Config is the configuration object for Google Gemini. It is used to configure Google Gemini and is passed to GoogleAI when it is created.</p>"},{"location":"llm/googleai.html#director.llm.googleai.GoogleAIConfig","title":"director.llm.googleai.GoogleAIConfig","text":"<p>               Bases: <code>BaseLLMConfig</code></p> <p>GoogleAI Config</p>"},{"location":"llm/googleai.html#googleai-interface","title":"GoogleAI Interface","text":"<p>GoogleAI is the LLM used by the agents and tools. It is used to generate responses to messages.</p>"},{"location":"llm/googleai.html#director.llm.googleai.GoogleAI","title":"director.llm.googleai.GoogleAI","text":"<pre><code>GoogleAI(config=None)\n</code></pre> <p>               Bases: <code>BaseLLM</code></p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>GoogleAIConfig</code> <p>GoogleAI Config</p> <code>None</code> Source code in <code>backend/director/llm/googleai.py</code> <pre><code>def __init__(self, config: GoogleAIConfig = None):\n    \"\"\"\n    :param config: GoogleAI Config\n    \"\"\"\n    if config is None:\n        config = GoogleAIConfig()\n    super().__init__(config=config)\n    try:\n        import openai\n    except ImportError:\n        raise ImportError(\"Please install OpenAI python library.\")\n\n    self.client = openai.OpenAI(\n        api_key=self.api_key, base_url=self.api_base\n    )\n</code></pre>"},{"location":"llm/googleai.html#director.llm.googleai.GoogleAI._format_messages","title":"_format_messages","text":"<pre><code>_format_messages(messages)\n</code></pre> <p>Format the messages to the format that Google Gemini expects.</p> Source code in <code>backend/director/llm/googleai.py</code> <pre><code>def _format_messages(self, messages: list):\n    \"\"\"Format the messages to the format that Google Gemini expects.\"\"\"\n    formatted_messages = []\n\n    for message in messages:\n        if message[\"role\"] == \"assistant\" and message.get(\"tool_calls\"):\n            formatted_messages.append(\n                {\n                    \"role\": message[\"role\"],\n                    \"content\": message[\"content\"],\n                    \"tool_calls\": [\n                        {\n                            \"id\": tool_call[\"id\"],\n                            \"function\": {\n                                \"name\": tool_call[\"tool\"][\"name\"],\n                                \"arguments\": json.dumps(\n                                    tool_call[\"tool\"][\"arguments\"]\n                                ),\n                            },\n                            \"type\": tool_call[\"type\"],\n                        }\n                        for tool_call in message[\"tool_calls\"]\n                    ],\n                }\n            )\n        else:\n            formatted_messages.append(message)\n\n    return formatted_messages\n</code></pre>"},{"location":"llm/googleai.html#director.llm.googleai.GoogleAI._format_tools","title":"_format_tools","text":"<pre><code>_format_tools(tools)\n</code></pre> <p>Format the tools to the format that Gemini expects.</p> <p>Example::</p> <pre><code>[\n    {\n        \"type\": \"function\",\n        \"function\": {\n            \"name\": \"get_weather\",\n            \"description\": \"Get the weather in a given location\",\n            \"parameters\": {\n                \"type\": \"object\",\n                \"properties\": {\n                    \"location\": {\n                        \"type\": \"string\",\n                        \"description\": \"The city and state, e.g. Chicago, IL\"\n                    },\n                    \"unit\": {\n                        \"type\": \"string\",\n                        \"enum\": [\"celsius\", \"fahrenheit\"]\n                    }\n                },\n                \"required\": [\"location\"]\n            }\n        }\n    }\n]\n</code></pre> Source code in <code>backend/director/llm/googleai.py</code> <pre><code>def _format_tools(self, tools: list):\n    \"\"\"Format the tools to the format that Gemini expects.\n\n    **Example**::\n\n        [\n            {\n                \"type\": \"function\",\n                \"function\": {\n                    \"name\": \"get_weather\",\n                    \"description\": \"Get the weather in a given location\",\n                    \"parameters\": {\n                        \"type\": \"object\",\n                        \"properties\": {\n                            \"location\": {\n                                \"type\": \"string\",\n                                \"description\": \"The city and state, e.g. Chicago, IL\"\n                            },\n                            \"unit\": {\n                                \"type\": \"string\",\n                                \"enum\": [\"celsius\", \"fahrenheit\"]\n                            }\n                        },\n                        \"required\": [\"location\"]\n                    }\n                }\n            }\n        ]\n    \"\"\"\n    return [\n        {\n            \"type\": \"function\",\n            \"function\": {\n                \"name\": tool.get(\"name\", \"\"),\n                \"description\": tool.get(\"description\", \"\"),\n                \"parameters\": tool.get(\"parameters\", {}),\n            },\n        }\n        for tool in tools\n        if tool.get(\"name\")\n    ]\n</code></pre>"},{"location":"llm/googleai.html#director.llm.googleai.GoogleAI.chat_completions","title":"chat_completions","text":"<pre><code>chat_completions(\n    messages, tools=[], stop=None, response_format=None\n)\n</code></pre> <p>Get chat completions using Gemini.</p> <p>docs: https://ai.google.dev/gemini-api/docs/openai</p> Source code in <code>backend/director/llm/googleai.py</code> <pre><code>def chat_completions(\n    self, messages: list, tools: list = [], stop=None, response_format=None\n):\n    \"\"\"Get chat completions using Gemini.\n\n    docs: https://ai.google.dev/gemini-api/docs/openai\n    \"\"\"\n    params = {\n        \"model\": self.chat_model,\n        \"messages\": self._format_messages(messages),\n        \"temperature\": self.temperature,\n        \"max_tokens\": self.max_tokens,\n        \"top_p\": self.top_p,\n        \"timeout\": self.timeout,\n    }\n\n    if tools:\n        params[\"tools\"] = self._format_tools(tools)\n        params[\"tool_choice\"] = \"auto\"\n\n    if response_format:\n        params[\"response_format\"] = response_format\n\n    try:\n        response = self.client.chat.completions.create(**params)\n    except Exception as e:\n        print(f\"Error: {e}\")\n        return LLMResponse(content=f\"Error: {e}\")\n\n    return LLMResponse(\n        content=response.choices[0].message.content or \"\",\n        tool_calls=[\n            {\n                \"id\": tool_call.id,\n                \"tool\": {\n                    \"name\": tool_call.function.name,\n                    \"arguments\": json.loads(tool_call.function.arguments),\n                },\n                \"type\": tool_call.type,\n            }\n            for tool_call in response.choices[0].message.tool_calls\n        ]\n        if response.choices[0].message.tool_calls\n        else [],\n        finish_reason=response.choices[0].finish_reason,\n        send_tokens=response.usage.prompt_tokens,\n        recv_tokens=response.usage.completion_tokens,\n        total_tokens=response.usage.total_tokens,\n        status=LLMResponseStatus.SUCCESS,\n    )\n</code></pre>"},{"location":"llm/interface.html","title":"Interface","text":""},{"location":"llm/interface.html#llm-interface","title":"LLM Interface","text":"<p>Base LLM is the base class for all LLMs. It provides a common interface for all LLMs to follow.</p>"},{"location":"llm/interface.html#base-llm-config","title":"Base LLM Config","text":"<p>Base LLM Config is the configuration object for an LLM. It is used to configure the LLM and is passed to the LLM when it is created.</p>"},{"location":"llm/interface.html#director.llm.base.BaseLLMConfig","title":"director.llm.base.BaseLLMConfig","text":"<p>               Bases: <code>BaseSettings</code></p> <p>Base configuration for all LLMs.</p> <p>Parameters:</p> Name Type Description Default <code>llm_type</code> <code>str</code> <p>Type of LLM. e.g. \"openai\", \"anthropic\", etc.</p> required <code>api_key</code> <code>str</code> <p>API key for the LLM.</p> required <code>api_base</code> <code>str</code> <p>Base URL for the LLM API.</p> required <code>chat_model</code> <code>str</code> <p>Model name for chat completions.</p> required <code>temperature</code> <code>str</code> <p>Sampling temperature for completions.</p> required <code>top_p</code> <code>float</code> <p>Top p sampling for completions.</p> required <code>max_tokens</code> <code>int</code> <p>Maximum tokens to generate.</p> required <code>timeout</code> <code>int</code> <p>Timeout for the request.</p> required"},{"location":"llm/interface.html#base-llm","title":"Base LLM","text":"<p>Base LLM is the base class for all LLMs. It provides a common interface for all LLMs to follow.</p>"},{"location":"llm/interface.html#director.llm.base.BaseLLM","title":"director.llm.base.BaseLLM","text":"<pre><code>BaseLLM(config)\n</code></pre> <p>               Bases: <code>ABC</code></p> <p>Interface for all LLMs. All LLMs should inherit from this class.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>BaseLLMConfig</code> <p>Configuration for the LLM.</p> required Source code in <code>backend/director/llm/base.py</code> <pre><code>def __init__(self, config: BaseLLMConfig):\n    \"\"\"\n    :param config: Configuration for the LLM.\n    \"\"\"\n    self.config = config\n    self.llm_type = config.llm_type\n    self.api_key = config.api_key\n    self.api_base = config.api_base\n    self.chat_model = config.chat_model\n    self.temperature = config.temperature\n    self.top_p = config.top_p\n    self.max_tokens = config.max_tokens\n    self.timeout = config.timeout\n    self.enable_langfuse = config.enable_langfuse\n</code></pre>"},{"location":"llm/interface.html#director.llm.base.BaseLLM.chat_completions","title":"chat_completions  <code>abstractmethod</code>","text":"<pre><code>chat_completions(messages, tools)\n</code></pre> <p>Abstract method for chat completions</p> Source code in <code>backend/director/llm/base.py</code> <pre><code>@abstractmethod\ndef chat_completions(self, messages: List[Dict], tools: List[Dict]) -&gt; LLMResponse:\n    \"\"\"Abstract method for chat completions\"\"\"\n    pass\n</code></pre>"},{"location":"llm/interface.html#llm-response","title":"LLM Response","text":"<p>LLM Response is the response object for an LLM. It is returned by the LLM after processing an input message.</p>"},{"location":"llm/interface.html#director.llm.base.LLMResponse","title":"director.llm.base.LLMResponse  <code>pydantic-model</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Response model for completions from LLMs.</p>"},{"location":"llm/openai.html","title":"OpenAI","text":""},{"location":"llm/openai.html#openai","title":"OpenAI","text":"<p>OpenAI extends the Base LLM and implements the OpenAI API.</p>"},{"location":"llm/openai.html#openai-config","title":"OpenAI Config","text":"<p>OpenAI Config is the configuration object for OpenAI. It is used to configure OpenAI and is passed to OpenAI when it is created.</p>"},{"location":"llm/openai.html#director.llm.openai.OpenaiConfig","title":"director.llm.openai.OpenaiConfig","text":"<p>               Bases: <code>BaseLLMConfig</code></p> <p>OpenAI Config</p>"},{"location":"llm/openai.html#openai-interface","title":"OpenAI Interface","text":"<p>OpenAI is the LLM used by the agents and tools. It is used to generate responses to messages.</p>"},{"location":"llm/openai.html#director.llm.openai.OpenAI","title":"director.llm.openai.OpenAI","text":"<pre><code>OpenAI(config=None)\n</code></pre> <p>               Bases: <code>BaseLLM</code></p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>OpenaiConfig</code> <p>OpenAI Config</p> <code>None</code> Source code in <code>backend/director/llm/openai.py</code> <pre><code>def __init__(self, config: OpenaiConfig = None):\n    \"\"\"\n    :param config: OpenAI Config\n    \"\"\"\n    if config is None:\n        config = OpenaiConfig()\n    super().__init__(config=config)\n    try:\n        import openai\n    except ImportError:\n        raise ImportError(\"Please install OpenAI python library.\")\n\n    self.client = openai.OpenAI(api_key=self.api_key, base_url=self.api_base)\n</code></pre>"},{"location":"llm/openai.html#director.llm.openai.OpenAI._format_messages","title":"_format_messages","text":"<pre><code>_format_messages(messages)\n</code></pre> <p>Format the messages to the format that OpenAI expects.</p> Source code in <code>backend/director/llm/openai.py</code> <pre><code>def _format_messages(self, messages: list):\n    \"\"\"Format the messages to the format that OpenAI expects.\"\"\"\n    formatted_messages = []\n    for message in messages:\n        if message[\"role\"] == \"assistant\" and message.get(\"tool_calls\"):\n            formatted_messages.append(\n                {\n                    \"role\": message[\"role\"],\n                    \"content\": message[\"content\"],\n                    \"tool_calls\": [\n                        {\n                            \"id\": tool_call[\"id\"],\n                            \"function\": {\n                                \"name\": tool_call[\"tool\"][\"name\"],\n                                \"arguments\": json.dumps(\n                                    tool_call[\"tool\"][\"arguments\"]\n                                ),\n                            },\n                            \"type\": tool_call[\"type\"],\n                        }\n                        for tool_call in message[\"tool_calls\"]\n                    ],\n                }\n            )\n        else:\n            formatted_messages.append(message)\n    return formatted_messages\n</code></pre>"},{"location":"llm/openai.html#director.llm.openai.OpenAI._format_tools","title":"_format_tools","text":"<pre><code>_format_tools(tools)\n</code></pre> <p>Format the tools to the format that OpenAI expects.</p> <p>Example::</p> <pre><code>[\n    {\n        \"type\": \"function\",\n        \"function\": {\n            \"name\": \"get_delivery_date\",\n            \"description\": \"Get the delivery date for a customer's order.\",\n            \"parameters\": {\n                \"type\": \"object\",\n                \"properties\": {\n                    \"order_id\": {\n                        \"type\": \"string\",\n                        \"description\": \"The customer's order ID.\"\n                    }\n                },\n                \"required\": [\"order_id\"],\n                \"additionalProperties\": False\n            }\n        }\n    }\n]\n</code></pre> Source code in <code>backend/director/llm/openai.py</code> <pre><code>def _format_tools(self, tools: list):\n    \"\"\"Format the tools to the format that OpenAI expects.\n\n    **Example**::\n\n        [\n            {\n                \"type\": \"function\",\n                \"function\": {\n                    \"name\": \"get_delivery_date\",\n                    \"description\": \"Get the delivery date for a customer's order.\",\n                    \"parameters\": {\n                        \"type\": \"object\",\n                        \"properties\": {\n                            \"order_id\": {\n                                \"type\": \"string\",\n                                \"description\": \"The customer's order ID.\"\n                            }\n                        },\n                        \"required\": [\"order_id\"],\n                        \"additionalProperties\": False\n                    }\n                }\n            }\n        ]\n    \"\"\"\n    formatted_tools = []\n    for tool in tools:\n        formatted_tools.append(\n            {\n                \"type\": \"function\",\n                \"function\": {\n                    \"name\": tool[\"name\"],\n                    \"description\": tool[\"description\"],\n                    \"parameters\": tool[\"parameters\"],\n                },\n                \"strict\": True,\n            }\n        )\n    return formatted_tools\n</code></pre>"},{"location":"llm/openai.html#director.llm.openai.OpenAI.chat_completions","title":"chat_completions","text":"<pre><code>chat_completions(\n    messages, tools=[], stop=None, response_format=None\n)\n</code></pre> <p>Get completions for chat.</p> <p>docs: https://platform.openai.com/docs/guides/function-calling</p> Source code in <code>backend/director/llm/openai.py</code> <pre><code>def chat_completions(\n    self, messages: list, tools: list = [], stop=None, response_format=None\n):\n    \"\"\"Get completions for chat.\n\n    docs: https://platform.openai.com/docs/guides/function-calling\n    \"\"\"\n    params = {\n        \"model\": self.chat_model,\n        \"messages\": self._format_messages(messages),\n        \"temperature\": self.temperature,\n        \"max_tokens\": self.max_tokens,\n        \"top_p\": self.top_p,\n        \"stop\": stop,\n        \"timeout\": self.timeout,\n    }\n    if tools:\n        params[\"tools\"] = self._format_tools(tools)\n        params[\"tool_choice\"] = \"auto\"\n\n    if response_format:\n        params[\"response_format\"] = response_format\n\n    try:\n        response = self.client.chat.completions.create(**params)\n    except Exception as e:\n        print(f\"Error: {e}\")\n        return LLMResponse(content=f\"Error: {e}\")\n\n    return LLMResponse(\n        content=response.choices[0].message.content or \"\",\n        tool_calls=[\n            {\n                \"id\": tool_call.id,\n                \"tool\": {\n                    \"name\": tool_call.function.name,\n                    \"arguments\": json.loads(tool_call.function.arguments),\n                },\n                \"type\": tool_call.type,\n            }\n            for tool_call in response.choices[0].message.tool_calls\n        ]\n        if response.choices[0].message.tool_calls\n        else [],\n        finish_reason=response.choices[0].finish_reason,\n        send_tokens=response.usage.prompt_tokens,\n        recv_tokens=response.usage.completion_tokens,\n        total_tokens=response.usage.total_tokens,\n        status=LLMResponseStatus.SUCCESS,\n    )\n</code></pre>"},{"location":"releases/notes.html","title":"Releases Notes","text":""},{"location":"releases/notes.html#010","title":"0.1.0","text":"<ul> <li>Initial release</li> </ul>"},{"location":"server/api.html","title":"API Routes","text":"<p>Routes are defined in the <code>routes</code> folder.</p>"},{"location":"server/api.html#agent-routes","title":"Agent routes","text":""},{"location":"server/api.html#get-agent","title":"GET /agent","text":"<p>Return the agent information</p> <pre><code>[\n    {\n        \"description\": \"This is an agent to summarize the given video of VideoDB.\",\n        \"name\": \"summary\"\n    },\n    {\n        \"description\": \"Get the download URLs of the VideoDB generated streams.\",\n        \"name\": \"download\"\n    },\n    {\n        \"description\": \"Agent to get information about the VideoDB pricing and usage.\",\n        \"name\": \"pricing\"\n    }\n]\n</code></pre>"},{"location":"server/api.html#session-routes","title":"Session routes","text":""},{"location":"server/api.html#get-session","title":"GET /session","text":"<p>Returns all the sessions</p> <pre><code>[\n    {\n        \"collection_id\": \"c-**\",\n        \"created_at\": 1729092742,\n        \"metadata\": {},\n        \"session_id\": \"52881f6b-7560-4844-ac35-52af41d07ab8\",\n        \"updated_at\": 1729092742,\n        \"video_id\": \"m-**\"\n    },\n    {\n        \"collection_id\": \"c-**\",\n        \"created_at\": 1729092642,\n        \"metadata\": {},\n        \"session_id\": \"6bf075a7-e7d4-4aba-985c-4cf0d3dc6f5b\",\n        \"updated_at\": 1729092642,\n        \"video_id\": \"m-**\"\n    }\n]\n</code></pre>"},{"location":"server/api.html#get-sessionsession_id","title":"GET /session/:session_id","text":"<p>Returns the session</p> <pre><code>{\n    \"collection_id\": \"c-**\",\n    \"conversation\": [\n        {\n            \"actions\": [],\n            \"agents\": [],\n            \"content\": [\n                {\n                    \"text\": \"No of video in my collection?\",\n                    \"type\": \"text\"\n                }\n            ],\n            \"conv_id\": \"b36c0a31-3c95-4f48-a1aa-daad351a30c3\",\n            \"created_at\": 1729852558,\n            \"metadata\": {},\n            \"msg_id\": \"1b753948-3672-446d-a7ab-ecd623d4244a\",\n            \"msg_type\": \"input\",\n            \"session_id\": \"33a41576-ffb3-4cec-993c-eedd728c21ac\",\n            \"status\": \"success\",\n            \"updated_at\": 1729852558\n        },\n        {\n            \"actions\": [\n                \"Reasoning the message..\"\n            ],\n            \"agents\": [],\n            \"content\": [\n                {\n                    \"agent_name\": null,\n                    \"status\": \"success\",\n                    \"status_message\": \"Here is the summary of the response\",\n                    \"text\": \"There are 36 videos in your collection.\",\n                    \"type\": \"text\"\n                }\n            ],\n            \"conv_id\": \"b36c0a31-3c95-4f48-a1aa-daad351a30c3\",\n            \"created_at\": 1729852562,\n            \"metadata\": {},\n            \"msg_id\": \"172985255862403.2\",\n            \"msg_type\": \"output\",\n            \"session_id\": \"33a41576-ffb3-4cec-993c-eedd728c21ac\",\n            \"status\": \"success\",\n            \"updated_at\": 1729852562\n        }\n    ],\n    \"created_at\": 1729852558,\n    \"metadata\": {},\n    \"session_id\": \"33a41576-ffb3-4cec-993c-eedd728c21ac\",\n    \"updated_at\": 1729852558,\n    \"video_id\": null\n}\n</code></pre>"},{"location":"server/api.html#delete-sessionsession_id","title":"DELETE /session/:session_id","text":"<p>Deletes the session</p> <pre><code>{\n    \"message\": \"Session deleted successfully.\"\n}\n</code></pre>"},{"location":"server/api.html#videodb-routes","title":"VideoDB routes","text":""},{"location":"server/api.html#get-videodbcollection","title":"GET /videodb/collection","text":"<p>Returns all the collections</p> <pre><code>[\n    {\n        \"description\": \"Test collection\",\n        \"id\": \"c-**\",\n        \"name\": \"Ankit Raj's collection\"\n    },\n    {\n        \"description\": \"Test1 collection\",\n        \"id\": \"c-**\",\n        \"name\": \"Ankit Raj's collection\"\n    },\n]\n</code></pre>"},{"location":"server/api.html#get-videodbcollectioncollection_id","title":"GET /videodb/collection/:collection_id","text":"<p>Returns the collection</p> <pre><code>{\n    \"description\": \"Test collection\",\n    \"id\": \"c-**\",\n    \"name\": \"Ankit Raj's collection\"\n}\n</code></pre>"},{"location":"server/api.html#get-videodbcollectioncollection_idvideo","title":"GET /videodb/collection/:collection_id/video","text":"<p>Returns all the videos in the collection</p> <pre><code>[\n    {\n        \"collection_id\": \"c-**\",\n        \"description\": null,\n        \"id\": \"m-**\",\n        \"length\": 1247.468844,\n        \"name\": \"Test video\",\n        \"stream_url\": \"https://stream.videodb.io/v3/published/manifests/test.m3u8\",\n        \"thumbnail_url\": null\n    },\n    {\n        \"collection_id\": \"c-**\",\n        \"description\": null,\n        \"id\": \"m-**\",\n        \"length\": 155.620136,\n        \"name\": \"Test video\",\n        \"stream_url\": \"https://stream.videodb.io/v3/published/manifests/test.m3u8\",\n        \"thumbnail_url\": null\n    },\n]\n</code></pre>"},{"location":"server/api.html#get-videodbcollectioncollection_idvideovideo_id","title":"GET /videodb/collection/:collection_id/video/:video_id","text":"<p>Returns the video</p> <pre><code>{\n    \"collection_id\": \"c-**\",\n    \"description\": null,\n    \"id\": \"m-**\",\n    \"length\": 1247.468844,\n    \"name\": \"Test video\",\n    \"stream_url\": \"https://stream.videodb.io/v3/published/manifests/test.m3u8\",\n    \"thumbnail_url\": null\n}\n</code></pre>"},{"location":"server/api.html#config-routes","title":"Config routes","text":""},{"location":"server/api.html#get-configcheck","title":"GET /config/check","text":"<p>Check the configuration</p> <pre><code>{\n    \"db_configured\": true,\n    \"llm_configured\": true,\n    \"videodb_configured\": true\n}\n</code></pre>"},{"location":"server/initialization.html","title":"Server","text":"<p>Server is the entry point for the application. Implemented using Flask and SocketIO for the API and WebSocket.</p>"},{"location":"server/initialization.html#server-config","title":"Server Config","text":"<p>By default, the server is configured to run in development mode. To run in production mode, set the <code>SERVER_ENV</code> environment variable to <code>production</code>.</p>"},{"location":"server/initialization.html#director.entrypoint.api.server.LocalAppConfig","title":"director.entrypoint.api.server.LocalAppConfig","text":"<p>               Bases: <code>BaseAppConfig</code></p> <p>Local configuration for the app. All the default values can be change using environment variables. e.g. <code>SERVER_PORT=8001</code></p>"},{"location":"server/initialization.html#director.entrypoint.api.server.LocalAppConfig.DEBUG","title":"DEBUG  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>DEBUG = 1\n</code></pre> <p>Debug mode for the app.</p>"},{"location":"server/initialization.html#director.entrypoint.api.server.LocalAppConfig.SECRET_KEY","title":"SECRET_KEY  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>SECRET_KEY = 'secret'\n</code></pre> <p>Secret key for the app.</p>"},{"location":"server/initialization.html#director.entrypoint.api.server.LocalAppConfig.LOGGING_CONFIG","title":"LOGGING_CONFIG  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>LOGGING_CONFIG = LOGGING_CONFIG\n</code></pre> <p>Logging configuration for the app.</p>"},{"location":"server/initialization.html#director.entrypoint.api.server.LocalAppConfig.DB_TYPE","title":"DB_TYPE  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>DB_TYPE = getenv('DB_TYPE', 'sqlite')\n</code></pre> <p>Database type for the app.</p>"},{"location":"server/initialization.html#director.entrypoint.api.server.LocalAppConfig.HOST","title":"HOST  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>HOST = '0.0.0.0'\n</code></pre> <p>Host for the app.</p>"},{"location":"server/initialization.html#director.entrypoint.api.server.LocalAppConfig.PORT","title":"PORT  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>PORT = 8000\n</code></pre> <p>Port for the app.</p>"},{"location":"server/initialization.html#director.entrypoint.api.server.LocalAppConfig.TESTING","title":"TESTING  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>TESTING = 0\n</code></pre> <p>Testing mode for the app.</p>"},{"location":"server/initialization.html#director.entrypoint.api.server.ProductionAppConfig","title":"director.entrypoint.api.server.ProductionAppConfig","text":"<p>               Bases: <code>BaseAppConfig</code></p> <p>Production configuration for the app. All the default values can be change using environment variables. e.g. SERVER_PORT=8001</p>"},{"location":"server/initialization.html#director.entrypoint.api.server.ProductionAppConfig.LOGGING_CONFIG","title":"LOGGING_CONFIG  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>LOGGING_CONFIG = LOGGING_CONFIG\n</code></pre> <p>Logging configuration for the app.</p>"},{"location":"server/initialization.html#director.entrypoint.api.server.ProductionAppConfig.DB_TYPE","title":"DB_TYPE  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>DB_TYPE = getenv('DB_TYPE', 'sqlite')\n</code></pre> <p>Database type for the app.</p>"},{"location":"server/initialization.html#director.entrypoint.api.server.ProductionAppConfig.HOST","title":"HOST  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>HOST = '0.0.0.0'\n</code></pre> <p>Host for the app.</p>"},{"location":"server/initialization.html#director.entrypoint.api.server.ProductionAppConfig.PORT","title":"PORT  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>PORT = 8000\n</code></pre> <p>Port for the app.</p>"},{"location":"server/initialization.html#director.entrypoint.api.server.ProductionAppConfig.DEBUG","title":"DEBUG  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>DEBUG = 0\n</code></pre> <p>Debug mode for the app.</p>"},{"location":"server/initialization.html#director.entrypoint.api.server.ProductionAppConfig.TESTING","title":"TESTING  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>TESTING = 0\n</code></pre> <p>Testing mode for the app.</p>"},{"location":"server/initialization.html#director.entrypoint.api.server.ProductionAppConfig.SECRET_KEY","title":"SECRET_KEY  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>SECRET_KEY = 'production'\n</code></pre> <p>Secret key for the app.</p>"},{"location":"server/initialization.html#server-initialization","title":"Server Initialization","text":""},{"location":"server/initialization.html#director.entrypoint.api.create_app","title":"director.entrypoint.api.create_app","text":"<pre><code>create_app(app_config)\n</code></pre> <p>Create a Flask app using the app factory pattern.</p> <p>Parameters:</p> Name Type Description Default <code>app_config</code> <code>object</code> <p>The configuration object to use.</p> required <p>Returns:</p> Type Description <p>A Flask app.</p> Source code in <code>backend/director/entrypoint/api/__init__.py</code> <pre><code>def create_app(app_config: object):\n    \"\"\"\n    Create a Flask app using the app factory pattern.\n\n    :param app_config: The configuration object to use.\n    :return: A Flask app.\n    \"\"\"\n    app = Flask(__name__)\n\n    # Set the app config\n    app.config.from_object(app_config)\n    app.config.from_prefixed_env(app_config.ENV_PREFIX)\n    CORS(app)\n\n    # Init the socketio and attach it to the app\n    socketio.init_app(\n        app,\n        cors_allowed_origins=\"*\",\n        logger=True,\n        engineio_logger=True,\n        reconnection=False if app.config[\"DEBUG\"] else True,\n    )\n    app.socketio = socketio\n\n    # Set the logging config\n    dictConfig(app.config[\"LOGGING_CONFIG\"])\n\n    with app.app_context():\n        from director.entrypoint.api import errors\n\n    # register blueprints\n    app.register_blueprint(agent_bp)\n    app.register_blueprint(session_bp)\n    app.register_blueprint(videodb_bp)\n    app.register_blueprint(config_bp)\n\n    # register socket namespaces\n    socketio.on_namespace(ChatNamespace(\"/chat\"))\n\n    return app\n</code></pre>"},{"location":"server/socketio.html","title":"Socket.io","text":""},{"location":"server/socketio.html#websocket-namespace","title":"WebSocket Namespace","text":"<p>WebSocket routes are defined in the <code>sockets</code> folder.</p>"},{"location":"server/socketio.html#chat-namespace","title":"Chat Namespace","text":""},{"location":"server/socketio.html#director.entrypoint.api.socket_io.ChatNamespace","title":"director.entrypoint.api.socket_io.ChatNamespace","text":"<p>               Bases: <code>Namespace</code></p> <p>Chat namespace for socket.io</p>"},{"location":"server/socketio.html#director.entrypoint.api.socket_io.ChatNamespace.on_chat","title":"on_chat","text":"<pre><code>on_chat(message)\n</code></pre> <p>Handle chat messages</p> Source code in <code>backend/director/entrypoint/api/socket_io.py</code> <pre><code>def on_chat(self, message):\n    \"\"\"Handle chat messages\"\"\"\n    chat_handler = ChatHandler(\n        db=load_db(os.getenv(\"SERVER_DB_TYPE\", app.config[\"DB_TYPE\"]))\n    )\n    chat_handler.chat(message)\n</code></pre>"},{"location":"utilities/exceptions.html","title":"Exceptions","text":""},{"location":"utilities/exceptions.html#exceptions","title":"Exceptions","text":""},{"location":"utilities/exceptions.html#director.utils.exceptions.DirectorException","title":"director.utils.exceptions.DirectorException","text":"<pre><code>DirectorException(message='An error occurred.', **kwargs)\n</code></pre> <p>               Bases: <code>Exception</code></p> <p>Base class for exceptions in this module.</p> Source code in <code>backend/director/utils/exceptions.py</code> <pre><code>def __init__(self, message=\"An error occurred.\", **kwargs):\n    super(ValueError, self).__init__(message)\n</code></pre>"},{"location":"utilities/exceptions.html#director.utils.exceptions.AgentException","title":"director.utils.exceptions.AgentException","text":"<pre><code>AgentException(\n    message=\"An error occurred in the agent\", **kwargs\n)\n</code></pre> <p>               Bases: <code>DirectorException</code></p> <p>Exception raised for errors in the agent.</p> Source code in <code>backend/director/utils/exceptions.py</code> <pre><code>def __init__(self, message=\"An error occurred in the agent\", **kwargs):\n    super(ValueError, self).__init__(message)\n</code></pre>"},{"location":"utilities/exceptions.html#director.utils.exceptions.ToolException","title":"director.utils.exceptions.ToolException","text":"<pre><code>ToolException(\n    message=\"An error occurred in the tool\", **kwargs\n)\n</code></pre> <p>               Bases: <code>DirectorException</code></p> <p>Exception raised for errors in the tool.</p> Source code in <code>backend/director/utils/exceptions.py</code> <pre><code>def __init__(self, message=\"An error occurred in the tool\", **kwargs):\n    super(ValueError, self).__init__(message)\n</code></pre>"}]}